{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**BIF7010 | Bioinformatique des structures**\n",
    "\n",
    "UQAM - Hiver 2019\n",
    "\n",
    "Amine Remita\n",
    "\n",
    "\n",
    "**Apprentissage automatique - Partie 3**\n",
    "\n",
    "\n",
    "* Évaluation de l'apprentissage\n",
    "* Applications de l'apprentissage automatique en bioinformatique\n",
    "\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a>\n",
    "BIF7101_S3 by Amine Remita is licensed under a Creative Commons Attribution-\n",
    "ShareAlike 4.0 International License.\n",
    "\n",
    "\n",
    "Quelques sous-sections et figures sont prises (avec autorisation) à partir des cours de Mohamed Bouguessa Ph.D. (DIC9370) et Ahmed Halioui Ph.D. (BIF7101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rappel \n",
    "\n",
    "* Prétraitement de données\n",
    "* Apprentissage supervisé\n",
    "* Apprentissage non supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Évaluation de l’apprentissage\n",
    "\n",
    "### Utilisation d’un échantillon de test\n",
    "\n",
    "* La méthode la plus simple pour estimer la qualité d’un algorithme d’apprentissage est de diviser l’ensemble des exemples en deux ensembles indépendants : le premier, noté $A$, est utilisé pour l’apprentissage, le second, noté $T$, sert à mesurer sa qualité.\n",
    "* $T$ est l’échantillon de test tel que : $S = A ∪ T$ et $A ∩ T = Φ$\n",
    "* La mesure des erreurs commises par l’algorithme d’apprentissage sur l’ensemble de test T est une estimation de sa qualité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = np.array(iris.target)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### La validation croisée\n",
    "\n",
    "* Diviser les données d’appentissage $S$ en k sous-échantillons de tailles égales\n",
    "* Répeter\n",
    "    * Retenir l’un de ces échantillons ($i$). \n",
    "    * Entrainer l’algorithme $C$ sur l’ensemble $S − i$\n",
    "    * Mesurer le taux d’erreur $R_i(C)$ sur l’ensemble de test $i$\n",
    "* Recommencer le processus décrit ci-dessus pour chaque échantillon $i$ \n",
    "* L’erreur estimée finale est donnée par la moyenne des erreurs mesurées\n",
    "\n",
    "<img src=\"figs/cross_validation.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "from pprint import pprint\n",
    "\n",
    "scoring = ['precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5, )\n",
    "\n",
    "pprint(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='f1_weighted')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leave-one-out\n",
    "\n",
    "Lorsque les données disponibles sont très peu nombreuses, il est possible de pousser à l’extrême la méthode de validation croisée en prenant k le nombre total d’exemple diponible (k = n). Dans ce cas, on ne retient à chaque fois qu’un seul exemple pour le test, et on répète l’apprentissage k fois pour tous les autres exemples d’apprentissage.\n",
    "\n",
    "\n",
    "<img src=\"figs/leave.png\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "\n",
    "scores = list()\n",
    "\n",
    "for train, test in loo.split(X):\n",
    "    # apprentissage\n",
    "    clf.fit(X[train], y[train])\n",
    "    # prédiction\n",
    "    y_pred = clf.predict(X[test])\n",
    "    # calcul score\n",
    "    scores.append(accuracy_score(y[test], y_pred))\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matrice de confusion\n",
    "\n",
    "Mesurer la qualité de généralisation du classificateur\n",
    "\n",
    "![](figs/matrice.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\"]\n",
    "y_pred = [\"A\", \"B\", \"A\", \"A\", \"B\", \"B\", \"B\"]\n",
    "\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calcul des mesures\n",
    "\n",
    "$ Rappel = \\frac{TP}{TP + FN} $\n",
    "(par rapport aux instances réelles)\n",
    "\n",
    "$ Précision  = \\frac{TP}{TP + FP} $\n",
    "(par rapport aux instances prédites)\n",
    "\n",
    "$ F-mesure = \\frac{2 (Precision \\times Rappel)}{Precision + Rappel)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "y_true = [0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 1, 1, 1]\n",
    "\n",
    "print(\"Rappel = {}\".format(recall_score(y_true, y_pred)))\n",
    "print(\"Précision = {}\".format(precision_score(y_true, y_pred)))\n",
    "print(\"F-measure = {}\".format(f1_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**True Positive Rate**\n",
    "(ou sensibilité)\n",
    "\n",
    "$ TPR = \\frac{TP}{TP + FN} $\n",
    "\t\t\t\t\n",
    "\n",
    "**True Negative Rate**\n",
    "(ou Spécificité)\n",
    "\n",
    "$ TNR = \\frac{TN}{FP + TN} $\n",
    "\t\t\t\t\n",
    "\n",
    "**False Positive Rate**\n",
    "(ou 1-Spécificité)\n",
    "\n",
    "$ FPR = \\frac{FP}{FP + TN} $ \n",
    "\t\t\t\t\n",
    "\n",
    "**False Negative Rate**\n",
    "\n",
    "$ FNR = \\frac{FN}{TP + FN} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Courbe ROC\n",
    "\n",
    "* ROC : Receiver Operating Characteristic\n",
    "* Elle met en ralation dans un graphique les taux de faux positifs (en abscisse) et les taux de vraix postifs (en ordonnée)\n",
    "\n",
    "* Elle est définie pour les problémes de deux classes\n",
    "\n",
    "\n",
    "<img src=\"figs/courbe_roc.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quelques points importants dans la courbe :\n",
    "\n",
    "* (FPR, TPR) :\n",
    "* (0, 0) prédit toujours négatif\n",
    "* (1, 1) prédit toujours positif\n",
    "* (0, 1) classification idéale\n",
    "* Ligne diagonale (ligne de hasard) : classification aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# exemple de https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "#y = np.array([1, 1, 2, 2])\n",
    "#scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "#fpr, tpr, thresholds = roc_curve(y, scores, pos_label=1)\n",
    "#print(thresholds)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Instanciation du classifieur\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Apprentissage/entrainement\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction \n",
    "scores = clf.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, scores[:,0], pos_label=0)\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "print(thresholds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications de l'apprentissage automatique en bioinformatique\n",
    "\n",
    "\n",
    "<img src=\"figs/learn_bio2.png\" width=\"800\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"figs/workflow_data.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utilisation de l’apprentissage supervisé (Jensen et Bateman 2011)\n",
    "\n",
    "<img src=\"figs/learn_bio1.png\" width=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Atelier : Prédiction des précurseurs des miARNs \n",
    "\n",
    "### Triplet-SVM (Xue et al., 2005)\n",
    "\n",
    "\n",
    "<img src=\"figs/triplet_svm_2005.png\" width=\"750\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partie 1 : Prédiction des vrais précurseurs des miARNs  de Homo Sapiens\n",
    "\n",
    "Fichiers d'entrée :\n",
    "* **mirna_hsa_fold.fasta** : séquences H. Sapiens de vrais précurseurs de miRNAs avec leurs repliements\n",
    "* **mirna_hsa_neg_fold.fasta** : séquences H. Sapiens de faux précurseurs de miRNAs avec leurs repliements\n",
    "\n",
    "\n",
    "1. Calculez le nombres d’occurrences des triplets des séquences avec **calculer_Xu_triplets.pl**\n",
    "\n",
    "2. Créez des jeux de données compatibles avec scikit-learn (matrice de données ***X*** et vecteur de classes ***y***) en fusionnant les données positives et négatives\n",
    "    * Deux classes : positive et negative\n",
    "\n",
    "3. Utilisez Scikit-learn pour l’apprentissage de differents algorithmes en utilisant une validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partie 2 : Prédiction des vrais précurseurs des miARNs de mirRBase\n",
    "\n",
    "Les séquences négatives des précurseurs peuvent être générées avec plusieurs approches\n",
    "\n",
    "* Brassage des nucléotides des séquences positives\n",
    "* Relocalisation de sous-séquences dans les séquences positives\n",
    "* Utilisation de séquences codantes dans le génome\n",
    "\n",
    "Refaire le même exercice de la partie 1 avec toutes les données de miRBase et deux jeux de données négatives différents\n",
    "\n",
    "Fichiers d'entrée :\n",
    "* **mirbase21_hairpins_fold.fasta** : séquences de vrais précurseurs de tout miRBase\n",
    "* **mirbase21_hairpins_neg1_fold.fasta** : séquences de faux précurseurs, approche 1\n",
    "* **mirbase21_hairpins_neg2_fold.fasta** : séquences de faux précurseurs, approche 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partie 3 : Comparaison des précurseurs des animaux et des plantes\n",
    "\n",
    "À partir du jeux de données construit à partir du fichier **mirbase21_hairpins_fold.fasta**:\n",
    "\n",
    "1. Générez un jeux de données des précurseurs d'animaux (homme, souris, etc.) et un autre des plantes (Arabidopsis, riz, mais etc.)\n",
    "    * Deux classes : animal et plante\n",
    "2. Utilisez Scikit-learn pour l’apprentissage de differents algorithmes en utilisant une validation croisée\n",
    "3. Est ce que les Triplets peuvent discriminer entre les précurseurs des animaux et des plantes ?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
